# -*- coding: utf-8 -*-
"""opti combi - projet square root rank.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZXNhyCQTIiKr94WOZSZOJ12rXZs8HsnT
"""

import numpy as np

def matrices1_ledm(n):
  M  = np.zeros((n,n))
  for i in range(n):
    for j in range(n):
      M[i,j]=(i-j)**2
  return M

from scipy.linalg import circulant
def matrices2_slackngon(n):
  M  = circulant(np.cos(np.pi/n)-np.cos(np.pi/n + 2*np.pi*np.arange(0,n,1)/n))
  M /= M[0,2]
  M  = np.maximum(M,0)
  for i in range(n):
    M[i,i] = 0
    if i<n-1:
      M[i,i+1] = 0
    else:
      M[i,0] = 0
  return M

def fobj(M,P,tol=1e-14):
  sing_values = np.linalg.svd(P*np.sqrt(M), compute_uv=False) # Calcul des valeurs singulières de la matrice P.*sqrt(M)
  ind_nonzero = np.where(sing_values > tol)[0]                # indices des valeurs > tolérance donnée
  return len(ind_nonzero), sing_values[ind_nonzero[-1]]       # on retourne objectif1=rang et objectif2=plus petite val sing. non-nulle

def compareP1betterthanP2(M,P1,P2):
  r1, s1 = fobj(M,P1) #on récupère les deux objectifs pour le pattern P1
  r2, s2 = fobj(M,P2) #on récupère les deux objectifs pour le pattern P2
  if r1 != r2:        #on traite les objectifs de façon lexicographique :
      return r1 < r2  # d'abord les valeurs du rang, et si celles-ci sont égales
  return s1 < s2      # alors on prend en compte la valeur de la + petite valeur singulière

def metaheuristic(M):
  bestPattern = np.ones(M.shape) #pattern initial

  ... #votre méthode

  return bestPattern

M = np.array([[4,0,1],[1,1,1],[1,1,0]])
P1 = np.array([[1,1,-1],[-1,1,1],[1,-1,-1]])
P2 = np.array([[-1,1,-1],[-1,-1,1],[1,1,-1]])
print(compareP1betterthanP2(M,P1,P2))
print(np.linalg.svd(P1*np.sqrt(M), compute_uv=False))

M = matrices2_slackngon(7)
P = np.array([[1,1,1,1,1,-1,1],[1,1,1,-1,1,-1,1],[1,1,1,1,1,1,-1],[1,-1,1,1,1,-1,-1],[1,1,-1,1,1,1,1],[1,-1,1,-1,-1,1,1],[1,1,1,1,1,1,1]])
print(fobj(M,P))



#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
import numpy as np
from scipy.linalg import circulant

def matrices1_ledm(n):
    M = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            M[i, j] = (i - j) ** 2
    return M

def matrices2_slackngon(n):
    M = circulant(np.cos(np.pi / n) - np.cos(np.pi / n + 2 * np.pi * np.arange(0, n, 1) / n))
    M /= M[0, 2]
    M = np.maximum(M, 0)
    for i in range(n):
        M[i, i] = 0
        if i < n - 1:
            M[i, i + 1] = 0
        else:
            M[i, 0] = 0
    return M

def fobj(M, P, tol=1e-14):
    sing_values = np.linalg.svd(P * np.sqrt(M), compute_uv=False)  # Valeurs singulières
    ind_nonzero = np.where(sing_values > tol)[0]                  # Indices > tolérance
    return len(ind_nonzero), sing_values[ind_nonzero[-1]]         # Retourne rang et petite valeur singulière

def compareP1betterthanP2(M, P1, P2):
    r1, s1 = fobj(M, P1)  # Objectifs pour P1
    r2, s2 = fobj(M, P2)  # Objectifs pour P2
    if r1 != r2:
        return r1 < r2    # Priorité au rang
    return s1 < s2        # Ensuite à la plus petite valeur singulière

def generate_neighbors(P):
    """
    Génère des voisins en inversant les signes de certains éléments de P.
    """
    neighbors = []
    for i in range(P.shape[0]):
        for j in range(P.shape[1]):
            neighbor = P.copy()
            neighbor[i, j] *= -1
            neighbors.append(neighbor)
    return neighbors

def metaheuristic(M, max_iter=100, tabu_size=10):
    """
    Métaheuristique basée sur l'algorithme Tabou pour résoudre le problème du square root rank.
    """
    bestPattern = np.ones(M.shape)  # Pattern initial
    tabu_list = []                 # Liste tabou
    best_objective = fobj(M, bestPattern)  # Objectif initial
    currentPattern = bestPattern.copy()

    for iteration in range(max_iter):
        neighbors = generate_neighbors(currentPattern)  # Génère des voisins
        best_neighbor = None
        best_neighbor_objective = None

        for neighbor in neighbors:
            if any(np.array_equal(neighbor, tabu) for tabu in tabu_list):
                continue  # Ignore les voisins dans la liste tabou

            neighbor_objective = fobj(M, neighbor)
            if best_neighbor is None or compareP1betterthanP2(M, neighbor, best_neighbor):
                best_neighbor = neighbor
                best_neighbor_objective = neighbor_objective

        if best_neighbor is None:
            break  # Aucun voisin valide trouvé

        currentPattern = best_neighbor

        # Mise à jour du meilleur résultat
        if compareP1betterthanP2(M, currentPattern, bestPattern):
            bestPattern = currentPattern
            best_objective = best_neighbor_objective

        # Mise à jour de la liste tabou
        tabu_list.append(currentPattern)
        if len(tabu_list) > tabu_size:
            tabu_list.pop(0)

        print(f"Iteration {iteration + 1}: Best rank so far: {best_objective[0]}")

    return bestPattern

# Exemple d'utilisation
M = np.array([[4, 0, 1], [1, 1, 1], [1, 1, 0]])
M = matrices2_slackngon(7)
best_pattern = metaheuristic(M)
print("Best pattern found:")
print(best_pattern)
print(fobj(M, best_pattern))
#%% GRASP

import numpy as np

def matrices1_ledm(n):
    M = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            M[i, j] = (i - j) ** 2
    return M

from scipy.linalg import circulant
def matrices2_slackngon(n):
    M = circulant(np.cos(np.pi / n) - np.cos(np.pi / n + 2 * np.pi * np.arange(0, n, 1) / n))
    M /= M[0, 2]
    M = np.maximum(M, 0)
    for i in range(n):
        M[i, i] = 0
        if i < n - 1:
            M[i, i + 1] = 0
        else:
            M[i, 0] = 0
    return M

def fobj(M, P, tol=1e-14):
    sing_values = np.linalg.svd(P * np.sqrt(M), compute_uv=False)  # Calcul des valeurs singulières de la matrice P.*sqrt(M)
    ind_nonzero = np.where(sing_values > tol)[0]  # indices des valeurs > tolérance donnée
    valeurs_non_nulles = [val for val in sing_values if val > tol]  # Filtrer les valeurs > tolérance
    return len(ind_nonzero), sing_values[ind_nonzero[-1]], valeurs_non_nulles  # on retourne objectif1=rang et objectif2=plus petite val sing. non-nulle

def compareP1betterthanP2(M, P1, P2):
    r1, s1, sv1 = fobj(M, P1)  # on récupère les deux objectifs pour le pattern P1
    r2, s2, sv2 = fobj(M, P2)  # on récupère les deux objectifs pour le pattern P2
    if r1 != r2:  # on traite les objectifs de façon lexicographique :
        return r1 < r2  # d'abord les valeurs du rang, et si celles-ci sont égales
    return s1 < s2  # alors on prend en compte la valeur de la plus petite valeur singulière

def construire_solution(M, alpha=0.5):
    m, n = M.shape  # m et n sont les dimensions de la matrice M
    candidats = []
    scores = []

    # Générer un ensemble de candidats
    for _ in range(100):  # Nombre de candidats à générer
        pattern = np.random.choice([1, -1], size=(m, n))  # Matrix de taille (m, n)
        rang, val, sing_values = fobj(M, pattern)
        candidats.append(pattern)
        scores.append((rang, val))

    # Déterminer cmin et cmax
    rangs, valeurs = zip(*scores)
    cmin = min(rangs)
    cmax = max(rangs)
    seuil = cmin + alpha * (cmax - cmin)

    # Construire la LCR
    LCR = [c for c, (r, _) in zip(candidats, scores) if r <= seuil]

    # Vérifier que la LCR n'est pas vide
    if not LCR:
        raise ValueError("La liste des candidats restreinte (LCR) est vide. Vérifiez les paramètres de alpha.")
    
    # Sélectionner une matrice dans la LCR
    index = np.random.randint(len(LCR))  # Générer un indice aléatoire
    return LCR[index]

# Recherche locale (simple inversion des coefficients pour améliorer)
def recherche_locale(M, P):
    m, n = P.shape
    meilleur_P = P.copy()
    meilleur_rang, meilleure_val, sv = fobj(M, meilleur_P)

    # Tester les voisins (une inversion à la fois)
    for i in range(m):
        for j in range(n):
            voisin = meilleur_P.copy()
            voisin[i, j] *= -1  # Inversion du coefficient
            rang, val, sv = fobj(M, voisin)
            if rang < meilleur_rang or (rang == meilleur_rang and val < meilleure_val):
                meilleur_P = voisin
                meilleur_rang, meilleure_val = rang, val

    return meilleur_P

def metaheuristic(M, iterations, alpha_init=0.3, alpha_step=0.1, alpha_bounds=(0.1, 0.9)):
    m, n = M.shape
    meilleur_pattern = np.ones((m, n))  # Pattern initial
    meilleur_rang, meilleure_val , sing_values = fobj(M, meilleur_pattern)
    alpha = alpha_init

    for it in range(iterations):
        # Phase constructive : générer une solution avec une LCR
        pattern_initial = construire_solution(M, alpha)
        
        # Phase de recherche locale : améliorer la solution
        pattern_ameliore = recherche_locale(M, pattern_initial)
        
        # Comparer avec la meilleure solution actuelle
        if compareP1betterthanP2(M, pattern_ameliore, meilleur_pattern):
            meilleur_pattern = pattern_ameliore
            meilleur_rang, meilleure_val, sing_values = fobj(M, meilleur_pattern)
            print(f"Iter {it+1}: Nouvelle meilleure solution avec rang={meilleur_rang}, val={meilleure_val:.6f}")

        # Mise à jour dynamique de alpha
        # Si une meilleure solution est trouvée, intensifier (réduire alpha)
        # Sinon, diversifier (augmenter alpha)
        if compareP1betterthanP2(M, pattern_ameliore, meilleur_pattern):
            alpha = max(alpha_bounds[0], alpha - alpha_step)  # Réduction de alpha
        else:
            alpha = min(alpha_bounds[1], alpha + alpha_step)  # Augmentation de alpha

    return meilleur_pattern

def lecture_fichier(path):
    with open(path, 'r') as fin:  # ouverture du fichier en mode lecture
        m, n = map(int, fin.readline().rstrip().split())  # lecture des dimensions m et n
        data = []  # initialisation d'une liste pour stocker les matrices
        
        # Lecture des lignes suivantes contenant les éléments de la matrice
        for _ in range(m):
            ligne = list(map(float, fin.readline().rstrip().split()))  
            data.append(ligne)  
        
    return np.array(data)   # Renvoie la matrice sous forme de tableau numpy

def ecriture_fichier(path, P, valeurs_sing):
    with open(path, 'w') as fout:
        # Écrire le pattern ligne par ligne
        for ligne in P:
            fout.write(' '.join(map(str, ligne)) + '\n')

        # Écrire les valeurs singulières non nulles
        for val in valeurs_sing:
            fout.write(f"{val}\n")
        
# Test de l'algorithme
if __name__ == "__main__":
    M = lecture_fichier('exempleslide_matrice.txt')
    print(M.shape)
    print(M)
    #M = matrices2_slackngon(7)  # Générer la matrice du problème

    best_pattern = metaheuristic(M, iterations=50, alpha_init=0.8, alpha_step=0.05)
    print("Meilleur pattern trouvé :")
    print(best_pattern)
    print("Résultat fobj : \n", fobj(M, best_pattern)[0],fobj(M, best_pattern)[1])
    
    # Écriture des résultats dans un fichier
    ecriture_fichier('resultat_pattern.txt',best_pattern, fobj(M, best_pattern)[2])

#%%

import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import circulant

def matrices1_ledm(n):
    M = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            M[i, j] = (i - j) ** 2
    return M

def matrices2_slackngon(n):
    M = circulant(np.cos(np.pi / n) - np.cos(np.pi / n + 2 * np.pi * np.arange(0, n, 1) / n))
    M /= M[0, 2]
    M = np.maximum(M, 0)
    for i in range(n):
        M[i, i] = 0
        if i < n - 1:
            M[i, i + 1] = 0
        else:
            M[i, 0] = 0
    return M

def fobj(M, P, tol=1e-14):
    sing_values = np.linalg.svd(P * np.sqrt(M), compute_uv=False)
    ind_nonzero = np.where(sing_values > tol)[0]
    valeurs_non_nulles = [val for val in sing_values if val > tol]
    return len(ind_nonzero), sing_values[ind_nonzero[-1]], valeurs_non_nulles

def compareP1betterthanP2(M, P1, P2):
    r1, s1, sv1 = fobj(M, P1)
    r2, s2, sv2 = fobj(M, P2)
    if r1 != r2:
        return r1 < r2
    return s1 < s2

def construction_heuristique(M):
    m, n = M.shape
    P = np.zeros((m, n))
    for i in range(m):
        for j in range(n):
            if i == j or i + j == n - 1:
                P[i, j] = 1
            else:
                P[i, j] = -1
    return P

def random_matrix(m,n, r):
    return ((np.random.rand(m,r)*10)@(np.random.rand(r,n)*10))**2

def perturbation_solution(P, perturbation_factor=0.6):
    """
    Introduit une perturbation aléatoire dans la solution pour favoriser la diversification.
    """
    m, n = P.shape
    for i in range(m):
        for j in range(n):
            if np.random.rand() < perturbation_factor:
                P[i, j] = -P[i, j]  # Changer le signe de certaines cases
    return P

def metaheuristic_aco(M, n_ants=10, n_iterations=100, alpha=1.0, beta=1.0, Q=1.0, rho=0.5):
    m, n = M.shape
    tau = np.ones((m, n))  # Phéromones initiales
    eta = 1 / (np.abs(M) + 1e-10)  # Visibilité initiale

    best_pattern = construction_heuristique(M)
    best_objective = fobj(M, best_pattern)  # Initialisation (rang, valeur singulière)

    for t in range(n_iterations):
        patterns = []
        objectives = []

        # --- Construction des solutions ---
        for k in range(n_ants):
            P = best_pattern.copy()
            for i in range(m):
                for j in range(n):
                    prob = (tau[i, j]**alpha) * (eta[i, j]**beta)
                    if np.random.rand() < prob / (2 * prob):
                        P[i, j] = 1
                    else:
                        P[i, j] = -1
            patterns.append(P)
            objectives.append(fobj(M, P))

        # --- Évaluation et mise à jour du meilleur ---
        for pattern, obj in zip(patterns, objectives):
            if compareP1betterthanP2(M, pattern, best_pattern if best_pattern is not None else pattern):
                best_pattern = pattern
                best_objective = obj

        # --- Mise à jour des phéromones ---
        tau *= (1 - rho)
        for pattern, obj in zip(patterns, objectives):
            rank, smallest_sv, _ = obj
            contribution = Q / (1 + rank + smallest_sv)
            tau += contribution * pattern

        # --- Adaptation dynamique ---
        if t % 10 == 0:  # Ajuste chaque 10 itérations
            if np.var([obj[0] for obj in objectives]) < 0.1:  # Convergence rapide
                beta += 0.1
            else:
                alpha += 0.1
            rho = max(0.1, rho - 0.01)  # Réduit lentement l'évaporation

        # Suivi
        print(f"Itération {t + 1}/{n_iterations} : Meilleur rang = {best_objective[0]}, Plus petite valeur singulière = {best_objective[1]}")

    return best_pattern


def lecture_fichier(path):
    with open(path, 'r') as fin:
        m, n = map(int, fin.readline().rstrip().split())
        data = []
        for _ in range(m):
            ligne = list(map(float, fin.readline().rstrip().split()))  
            data.append(ligne)  
    return np.array(data)

def ecriture_fichier(path, P, valeurs_sing):
    with open(path, 'w') as fout:
        for ligne in P:
            fout.write(' '.join(map(str, ligne)) + '\n')
        for val in valeurs_sing:
            fout.write(f"{val}\n")

# Test de l'algorithme
if __name__ == "__main__":
    m= 100
    n = 100
    r = 2
    #M = lecture_fichier('correl5_matrice.txt')
    #M = lecture_fichier('exempleslide_matrice.txt')
    M = random_matrix(m, n, r)
    
    
    best_pattern = metaheuristic_aco(M, n_ants=15, n_iterations=100, alpha=1.0, beta=2.0, Q=1.0, evaporation_rate=0.1, diversification_factor=0.4)
    
    print("Meilleur pattern trouvé :")
    print(best_pattern)
    print("Résultat fobj : \n", fobj(M, best_pattern)[0],fobj(M, best_pattern)[1])
    
    ecriture_fichier('resultat_pattern.txt', best_pattern, fobj(M, best_pattern)[2])
#%%
import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import circulant

def matrices1_ledm(n):
    M = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            M[i, j] = (i - j) ** 2
    return M

def matrices2_slackngon(n):
    M = circulant(np.cos(np.pi / n) - np.cos(np.pi / n + 2 * np.pi * np.arange(0, n, 1) / n))
    M /= M[0, 2]
    M = np.maximum(M, 0)
    for i in range(n):
        M[i, i] = 0
        if i < n - 1:
            M[i, i + 1] = 0
        else:
            M[i, 0] = 0
    return M

def fobj(M, P, tol=1e-14):
    sing_values = np.linalg.svd(P * np.sqrt(M), compute_uv=False)
    ind_nonzero = np.where(sing_values > tol)[0]
    valeurs_non_nulles = [val for val in sing_values if val > tol]
    return len(ind_nonzero), sing_values[ind_nonzero[-1]], valeurs_non_nulles

def compareP1betterthanP2(M, P1, P2):
    r1, s1, sv1 = fobj(M, P1)
    r2, s2, sv2 = fobj(M, P2)
    if r1 != r2:
        return r1 < r2
    return s1 < s2

def perturbation_solution(P, perturbation_factor=0.6):
    """
    Introduit une perturbation aléatoire dans la solution pour favoriser la diversification.
    """
    m, n = P.shape
    for i in range(m):
        for j in range(n):
            if np.random.rand() < perturbation_factor:
                P[i, j] = -P[i, j]  # Changer le signe de certaines cases
    return P

def initialiser_pheromones(m, n, valeur_initiale=0.4):
    """Initialise la matrice des phéromones."""
    return np.full((m, n), valeur_initiale)

def calculer_visibilite(M):
    """Calcule la visibilité (heuristique) basée sur la matrice donnée M."""
    eta = 1 / (M + 1e-10)  # Inverser M pour donner plus d'importance aux petites valeurs
    return eta

def calcul_probabilite(i, j, tau, eta, alpha, beta, options_disponibles):
    """Calcule la probabilité pour aller de i à j."""
    numerateur = (tau[i, j] ** alpha) * (eta[i, j] ** beta)
    denominateur = sum((tau[i, k] ** alpha) * (eta[i, k] ** beta) for k in options_disponibles)
    if denominateur == 0:
        return 1 / len(options_disponibles)  # Distribution uniforme
    return numerateur / denominateur

def construire_solution(M, tau, eta, alpha, beta):
    """Construit une solution pour une fourmi."""
    m, n = M.shape
    solution = []
    options_disponibles = list(range(n))
    P = np.zeros((m, n))  # Matrice des probabilités

    for i in range(m):
        for j in options_disponibles:
            P[i, j] = calcul_probabilite(i, j, tau, eta, alpha, beta, options_disponibles)
        # Sélection de j en fonction de P[i, :]
        j = np.random.choice(options_disponibles, p=P[i, options_disponibles] / P[i, options_disponibles].sum())
        solution.append((i, j))
        options_disponibles.remove(j)  # Mise à jour des options disponibles

    return solution

def evaluer_solution(solution, M):
    """Évalue une solution en fonction de la matrice M."""
    score = sum(M[i, j] for i, j in solution)
    return score

def mise_a_jour_pheromones(tau, solutions, rho, Q):
    """Met à jour la matrice des phéromones."""
    tau *= (1 - rho)  # Évaporation des phéromones
    for solution, qualite in solutions:
        for (i, j) in solution:
            tau[i, j] += Q / qualite  # Dépôt de phéromones proportionnel à la qualité

def metaheuristic_aco(M, n_ants=10, n_iterations=100, alpha=1.0, beta=1.0, Q=1.0, rho=0.5):
    m, n = M.shape
    tau = initialiser_pheromones(m, n)  # Phéromones initiales
    eta = calculer_visibilite(M)  # Visibilité initiale

    best_pattern = np.zeros((m, n))  # Solution de départ
    best_objective = float('inf')  # Score initial élevé

    for t in range(n_iterations):
        solutions = []
        for _ in range(n_ants):
            solution = construire_solution(M, tau, eta, alpha, beta)
            score = evaluer_solution(solution, M)
            solutions.append((solution, score))

            if score < best_objective:
                best_pattern = solution
                best_objective = score

        mise_a_jour_pheromones(tau, solutions, rho, Q)

        print(f"Itération {t + 1}/{n_iterations}: Meilleur score = {best_objective}")

    return best_pattern

def lecture_fichier(path):
    with open(path, 'r') as fin:
        m, n = map(int, fin.readline().rstrip().split())
        data = []
        for _ in range(m):
            ligne = list(map(float, fin.readline().rstrip().split()))  
            data.append(ligne)  
    return np.array(data)

def ecriture_fichier(path, P, valeurs_sing):
    with open(path, 'w') as fout:
        for ligne in P:
            fout.write(' '.join(map(str, ligne)) + '\n')
        for val in valeurs_sing:
            fout.write(f"{val}\n")

def random_matrix(m, n, r):
    return ((np.random.rand(m, r) * 10) @ (np.random.rand(r, n) * 10)) ** 2

# Test de l'algorithme
if __name__ == "__main__":
    m = 6
    n = 7
    r = 2
    M = random_matrix(m, n, r)
    #M = lecture_fichier('correl5_matrice.txt')
    #M = lecture_fichier('exempleslide_matrice.txt')
    best_pattern = metaheuristic_aco(M, n_ants=15, n_iterations=100, alpha=1.0, beta=2.0, Q=1.0, rho=0.1)

    print("Meilleur pattern trouvé :")
    print(best_pattern)
    print("Résultat fobj : \n", fobj(M, best_pattern)[0], fobj(M, best_pattern)[1])

    ecriture_fichier('resultat_pattern.txt', best_pattern, fobj(M, best_pattern)[2])
